{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "CQlGJduBLJyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41d080c-ae09-4dba-a925-2664cade41f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.55.3\n",
            "  Downloading openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.55.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.55.3) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.55.3) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.55.3) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.3) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (2.27.2)\n",
            "Downloading openai-1.55.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.13.3\n",
            "    Uninstalling openai-1.13.3:\n",
            "      Successfully uninstalled openai-1.13.3\n",
            "Successfully installed openai-1.55.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.55.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1712333180112
        },
        "id": "A_Wso_cnLJyi"
      },
      "outputs": [],
      "source": [
        "# Add Azure OpenAI package\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1712333182445
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "GiXgjC4OLJyk"
      },
      "outputs": [],
      "source": [
        "azure_oai_endpoint = \"https://pikachu.openai.azure.com/\"\n",
        "azure_oai_key = \"\"\n",
        "azure_oai_deployment = \"kiran\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1712333183879
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "_I8RWNoNLJyp"
      },
      "outputs": [],
      "source": [
        "# Initialize the Azure OpenAI client\n",
        "client = AzureOpenAI(azure_endpoint = azure_oai_endpoint,api_key=azure_oai_key, api_version=\"2024-02-15-preview\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1712333189626
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "43p7KAWbLJyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0ba97b-225d-4b95-e293-c6eee0d388f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-B5ona7NEKmZnYgbnk5fI3UU2K9tCM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Well, polar bears are more into fish and seals, but I'm sure if you offered them a pizza, they would give it a try. Who knows, maybe they would become the first polar bear pizzaholics!\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1740726610, model='gpt-35-turbo-16k', object='chat.completion', service_tier=None, system_fingerprint='fp_0165350fbb', usage=CompletionUsage(completion_tokens=45, prompt_tokens=60, total_tokens=105, completion_tokens_details=None, prompt_tokens_details=None), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=400,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do polar bears support pizzas too?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1712333189871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "7k9K_AgVLJyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b438ee9-302b-4b59-ebf0-195ab5037708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Well, polar bears are more into fish and seals, but I'm sure if you offered them a pizza, they would give it a try. Who knows, maybe they would become the first polar bear pizzaholics!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_text = response.choices[0].message.content\n",
        "\n",
        "# Print the response\n",
        "print(\"Response: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "biaMGR21LJys"
      },
      "source": [
        "**Maintain Chat History**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1712333260307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "4RbGZ66eLJyt"
      },
      "outputs": [],
      "source": [
        "# To maintain chat hisotry, we initialize messages array and append all interactions to the messages array\n",
        "messages_array = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"}\n",
        "\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1712333261573
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "kXdozrkyLJyu"
      },
      "outputs": [],
      "source": [
        "input_text = \"Do polar bears support pizzas too?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1712333265598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Or7FLhClLJyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc285fb-5bc1-456c-8c58-efd7d8c9d457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Oh, absolutely! Polar bears are big fans of pizzas. In fact, they have been known to have pizza parties on icebergs. Just make sure to bring extra toppings for them, like seal sausage and arctic anchovies.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "messages_array.append({\"role\": \"user\", \"content\": input_text})\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=1200,\n",
        "    messages=messages_array\n",
        ")\n",
        "generated_text = response.choices[0].message.content\n",
        "# Add generated text to messages array\n",
        "messages_array.append({\"role\": \"system\", \"content\": generated_text})\n",
        "\n",
        "# Print generated text\n",
        "print(\"Summary: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "8WWiiZzaLJyv"
      },
      "source": [
        "**Let's check out the messages array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712333314293
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "2VmH8jq3LJyv"
      },
      "outputs": [],
      "source": [
        "print(messages_array)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}